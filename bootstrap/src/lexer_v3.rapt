// ============================================================================
// LEXER.RAPT - Full lexer with ENUMS and MATCH! (Bootstrap v3)
// ============================================================================

import bootstrap.src.token

extern fn strlen(s: *char) -> int;
extern fn printf(format: *char, ...) -> int;

// Helper: Character classification using match expressions
fn char_category(c: char) -> int {
    // Returns: 0=other, 1=whitespace, 2=digit, 3=alpha, 4=underscore
    return match c {
        ' ' => 1,
        '\t' => 1,
        '\n' => 1,
        '\r' => 1,
        '0' => 2,
        '1' => 2,
        '2' => 2,
        '3' => 2,
        '4' => 2,
        '5' => 2,
        '6' => 2,
        '7' => 2,
        '8' => 2,
        '9' => 2,
        '_' => 4,
        _ => 0
    };
}

fn is_whitespace(c: char) -> int {
    return match c {
        ' ' => 1,
        '\t' => 1,
        '\n' => 1,
        '\r' => 1,
        _ => 0
    };
}

fn is_digit(c: char) -> int {
    if c >= '0' && c <= '9' { return 1; }
    return 0;
}

fn is_alpha(c: char) -> int {
    if c >= 'a' && c <= 'z' { return 1; }
    if c >= 'A' && c <= 'Z' { return 1; }
    if c == '_' { return 1; }
    return 0;
}

fn is_alnum(c: char) -> int {
    if is_alpha(c) != 0 { return 1; }
    if is_digit(c) != 0 { return 1; }
    return 0;
}

// Match keyword at current position - NOW WITH MATCH!
fn match_keyword(input: *char, start: int, end: int) -> TokenKind {
    let len = end - start;
    
    // We'll use match on length, then check the actual string
    // For now, keeping the old approach but returning TokenKind enum
    return match len {
        2 => match_keyword_len2(input, start),
        3 => match_keyword_len3(input, start),
        4 => match_keyword_len4(input, start),
        5 => match_keyword_len5(input, start),
        6 => match_keyword_len6(input, start),
        _ => TokenKind::IDENT
    };
}

fn match_keyword_len2(input: *char, start: int) -> TokenKind {
    if input[start] == 'f' && input[start + 1] == 'n' { return TokenKind::FN; }
    if input[start] == 'i' && input[start + 1] == 'f' { return TokenKind::IF; }
    if input[start] == 'a' && input[start + 1] == 's' { return TokenKind::AS; }
    return TokenKind::IDENT;
}

fn match_keyword_len3(input: *char, start: int) -> TokenKind {
    if input[start] == 'l' && input[start + 1] == 'e' && input[start + 2] == 't' { 
        return TokenKind::LET; 
    }
    if input[start] == 'm' && input[start + 1] == 'u' && input[start + 2] == 't' { 
        return TokenKind::MUT; 
    }
    if input[start] == 'f' && input[start + 1] == 'o' && input[start + 2] == 'r' { 
        return TokenKind::FOR; 
    }
    if input[start] == 'i' && input[start + 1] == 'n' && input[start + 2] == 't' { 
        return TokenKind::INT_TYPE; 
    }
    if input[start] == 'n' && input[start + 1] == 'e' && input[start + 2] == 'w' { 
        return TokenKind::NEW; 
    }
    return TokenKind::IDENT;
}

fn match_keyword_len4(input: *char, start: int) -> TokenKind {
    if input[start] == 'e' && input[start + 1] == 'l' && input[start + 2] == 's' && input[start + 3] == 'e' { 
        return TokenKind::ELSE; 
    }
    if input[start] == 'c' && input[start + 1] == 'h' && input[start + 2] == 'a' && input[start + 3] == 'r' { 
        return TokenKind::CHAR_TYPE; 
    }
    if input[start] == 'e' && input[start + 1] == 'n' && input[start + 2] == 'u' && input[start + 3] == 'm' { 
        return TokenKind::ENUM; 
    }
    return TokenKind::IDENT;
}

fn match_keyword_len5(input: *char, start: int) -> TokenKind {
    if input[start] == 'c' && input[start + 1] == 'o' && input[start + 2] == 'n' && input[start + 3] == 's' && input[start + 4] == 't' { 
        return TokenKind::CONST; 
    }
    if input[start] == 'w' && input[start + 1] == 'h' && input[start + 2] == 'i' && input[start + 3] == 'l' && input[start + 4] == 'e' { 
        return TokenKind::WHILE; 
    }
    if input[start] == 'm' && input[start + 1] == 'a' && input[start + 2] == 't' && input[start + 3] == 'c' && input[start + 4] == 'h' { 
        return TokenKind::MATCH; 
    }
    if input[start] == 'b' && input[start + 1] == 'r' && input[start + 2] == 'e' && input[start + 3] == 'a' && input[start + 4] == 'k' { 
        return TokenKind::BREAK; 
    }
    return TokenKind::IDENT;
}

fn match_keyword_len6(input: *char, start: int) -> TokenKind {
    if input[start] == 'r' && input[start + 1] == 'e' && input[start + 2] == 't' && input[start + 3] == 'u' && input[start + 4] == 'r' && input[start + 5] == 'n' { 
        return TokenKind::RETURN; 
    }
    if input[start] == 'i' && input[start + 1] == 'm' && input[start + 2] == 'p' && input[start + 3] == 'o' && input[start + 4] == 'r' && input[start + 5] == 't' { 
        return TokenKind::IMPORT; 
    }
    if input[start] == 'e' && input[start + 1] == 'x' && input[start + 2] == 'p' && input[start + 3] == 'o' && input[start + 4] == 'r' && input[start + 5] == 't' { 
        return TokenKind::EXPORT; 
    }
    if input[start] == 'e' && input[start + 1] == 'x' && input[start + 2] == 't' && input[start + 3] == 'e' && input[start + 4] == 'r' && input[start + 5] == 'n' { 
        return TokenKind::EXTERN; 
    }
    if input[start] == 's' && input[start + 1] == 't' && input[start + 2] == 'r' && input[start + 3] == 'u' && input[start + 4] == 'c' && input[start + 5] == 't' { 
        return TokenKind::STRUCT; 
    }
    return TokenKind::IDENT;
}

fn match_keyword_len8(input: *char, start: int) -> TokenKind {
    if input[start] == 'c' && input[start + 1] == 'o' && input[start + 2] == 'n' && input[start + 3] == 't' && 
       input[start + 4] == 'i' && input[start + 5] == 'n' && input[start + 6] == 'u' && input[start + 7] == 'e' { 
        return TokenKind::CONTINUE; 
    }
    return TokenKind::IDENT;
}

export fn tokenize(input: *char) -> int {
    printf("=== Starting tokenization ===\n");
    let i = 0;
    let len = strlen(input);
    let token_count = 0;
    
    while i < len {
        let c = input[i];
        let matched = 0;
        
        // Skip whitespace using match!
        let ws = is_whitespace(c);
        if ws != 0 {
            matched = 1;
            i = i + 1;
        }
        
        // Single-line comments
        if matched == 0 && c == '/' && i + 1 < len && input[i + 1] == '/' {
            matched = 1;
            i = i + 2;
            while i < len && input[i] != '\n' {
                i = i + 1;
            }
        }
        
        // Identifiers and keywords
        if matched == 0 && is_alpha(c) != 0 {
            matched = 1;
            let start = i;
            while i < len && is_alnum(input[i]) != 0 {
                i = i + 1;
            }
            let kind = match_keyword(input, start, i);
            token_count = token_count + 1;
            
            // Print token for debugging
            let kind_code = match kind {
                TokenKind::EOF => 0,
                TokenKind::IDENT => 1,
                TokenKind::FN => 40,
                TokenKind::LET => 41,
                TokenKind::IF => 45,
                TokenKind::MATCH => 54,
                _ => 999
            };
            printf("Token %d: kind=%d\n", token_count, kind_code);
        }
        
        // Integer literals
        if matched == 0 && is_digit(c) != 0 {
            matched = 1;
            let start = i;
            while i < len && is_digit(input[i]) != 0 {
                i = i + 1;
            }
            token_count = token_count + 1;
            printf("Token %d: INTEGER\n", token_count);
        }
        
        // Two-character operators - NOW WITH MATCH!
        if matched == 0 && i + 1 < len {
            let c2 = input[i + 1];
            
            // Try to match two-char operator
            let kind_opt = match_two_char_op(c, c2);
            if kind_opt >= 0 {
                matched = 1;
                token_count = token_count + 1;
                printf("Token %d: two-char op\n", token_count);
                i = i + 2;
            }
        }
        
        // Single-character tokens - NOW WITH MATCH!
        if matched == 0 {
            let kind_opt = match_single_char(c);
            if kind_opt >= 0 {
                matched = 1;
                token_count = token_count + 1;
                printf("Token %d: single-char\n", token_count);
                i = i + 1;
            }
        }
        
        // Unknown character - skip it
        if matched == 0 {
            i = i + 1;
        }
    }
    
    printf("=== Tokenization complete: %d tokens ===\n", token_count);
    return token_count;
}

// Helper: Match two-character operators
fn match_two_char_op(c1: char, c2: char) -> int {
    // Returns token kind code, or -1 if no match
    if c1 == '=' && c2 == '=' { return 27; }  // EQEQ
    if c1 == '!' && c2 == '=' { return 28; }  // NOTEQ
    if c1 == '<' && c2 == '=' { return 25; }  // LTEQ
    if c1 == '>' && c2 == '=' { return 26; }  // GTEQ
    if c1 == '&' && c2 == '&' { return 29; }  // ANDAND
    if c1 == '|' && c2 == '|' { return 30; }  // OROR
    if c1 == '-' && c2 == '>' { return 31; }  // ARROW
    if c1 == '=' && c2 == '>' { return 32; }  // FATARROW
    return -1;
}

// Helper: Match single-character tokens
fn match_single_char(c: char) -> int {
    // Returns token kind code, or -1 if no match
    return match c {
        '(' => 6,
        ')' => 7,
        '{' => 8,
        '}' => 9,
        '[' => 10,
        ']' => 11,
        ',' => 12,
        '.' => 13,
        ';' => 14,
        ':' => 15,
        '=' => 16,
        '+' => 17,
        '-' => 18,
        '*' => 19,
        '/' => 20,
        '%' => 21,
        '!' => 22,
        '<' => 23,
        '>' => 24,
        _ => -1
    };
}

